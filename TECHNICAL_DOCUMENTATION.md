# Umsetzer Video Chunking Pipeline - Technische Dokumentation

## üéØ √úberblick

Die Umsetzer Video Chunking Pipeline ist eine vollst√§ndige L√∂sung zur Verarbeitung von Video-Transkripten f√ºr intelligente Q&A-Systeme. Sie transkribiert Videos, teilt sie in semantische Chunks, generiert Embeddings und erm√∂glicht Retrieval-basierte Antworten.

## üèóÔ∏è Architektur

```
Video Input ‚Üí Transcription ‚Üí Semantic Chunking ‚Üí Embedding Generation ‚Üí Supabase Storage ‚Üí Mini Chat Agent
```

### Kernkomponenten:

1. **Transcription Pipeline** (`src/transcription/`)
   - OpenAI Whisper API Integration
   - Audio-Extraktion mit FFmpeg
   - Metadaten-Extraktion (Timestamps)
   - **Content-basierte Video-ID-Generierung** (robust gegen Dateinamen-√Ñnderungen)

2. **Semantic Chunking** (`src/chunking/`)
   - Basierend auf Chroma Research (89.7% Recall)
   - Multiple Strategien: semantic, recursive, video_optimized, fixed
   - Optimale Chunk-Gr√∂√üe: 400 Zeichen mit 50 Zeichen Overlap
   - **Intelligente Timestamp-Zuordnung** (verhindert "0" Timestamps)

3. **Embedding Generation** (`src/embedding/`)
   - OpenAI text-embedding-3-small (1.536 Dimensionen)
   - Batch-Verarbeitung f√ºr Effizienz
   - Supabase Integration mit pgvector
   - **Video-Level Duplikat-Erkennung** (verhindert mehrfache Verarbeitung)
   - **Content-basierte Chunk-Duplikat-Erkennung** (robust gegen Chunking-Parameter-√Ñnderungen)

4. **Mini Chat Agent** (`src/agent/`)
   - Retrieval-Augmented Generation (RAG)
   - GPT-4o-mini f√ºr Antwort-Generierung
   - Interaktive Chat-Sessions

## üìä Performance-Metriken

### Chunking-Ergebnisse (1-Stunden-Video):
- **Input**: 303 Segmente, 3.423 W√∂rter
- **Output**: 57 semantic chunks, 365 Zeichen Durchschnitt
- **Strategie**: Semantic (beste Balance)

### Kosten-Sch√§tzung:
- **Transkription**: ~$0.006 pro Stunde (Whisper API)
- **Embeddings**: $0.0007 pro Video (text-embedding-3-small)
- **Chat**: $0.0015 pro 1K Tokens (GPT-4o-mini)
- **Total f√ºr 300 Videos**: ~$0.21

### Kostenersparnis durch Duplikat-Erkennung:
- **Mehrfache Verarbeitung**: Verhindert unn√∂tige Transkriptionen
- **Batch-Runs**: Sicher vor versehentlichen Wiederholungen
- **Entwicklung**: Keine Kosten f√ºr Test-Runs
- **Wartung**: Effiziente Updates ohne Duplikate

## üîß Aktuelle Verbesserungen

### Intelligente Timestamp-Zuordnung:
- **Problem gel√∂st**: Keine "0" Timestamps mehr f√ºr Chunks, die nicht am Anfang stehen
- **Realistische Chunk-Dauern**: 10-120 Sekunden statt 20+ Minuten
- **Proportionale Zuordnung**: Basierend auf Chunk-Index und Text-L√§nge
- **Robuste Validierung**: Schutz vor unlogischen Timestamps
- **47x Verbesserung**: Durchschnittsdauer von 22,5 Min auf 0,5 Min reduziert

### Vereinfachte Architektur:
- **Speaker-Detection entfernt**: Whisper unterst√ºtzt keine native Speaker-Erkennung
- **Sauberer Code**: Fokus auf die wichtigen Features (Timestamps, Chunking, Embeddings)
- **Bessere Performance**: Weniger Datenverarbeitung ohne Speaker-Logik
- **Wartbarkeit**: Reduzierte Komplexit√§t

## üîí Robuste Identifikation

### Video-Level Duplikat-Erkennung:
```python
# 1. Generiere Video-ID (content-basiert)
video_id = self.whisper._generate_video_id(video_file)

# 2. Pr√ºfe ob Video bereits existiert
existing_check = self.processor.supabase_client.client.table("video_chunks").select("video_id").eq("video_id", video_id).limit(1).execute()

# 3. √úberspringe Verarbeitung wenn existiert
if existing_check.data:
    logger.info(f"Video {video_id} already exists in database. Skipping processing.")
    return True
```

**Vorteile:**
- ‚úÖ **Verhindert mehrfache Transkription** (kosteneinsparend)
- ‚úÖ **Verhindert mehrfache Verarbeitung** (zeitsparend)
- ‚úÖ **Robust** gegen Whisper API Nicht-Determinismus
- ‚úÖ **Effizient** durch fr√ºhe Erkennung

### Content-basierte Video-ID-Generierung:
```python
# Beispiel: video_6938124a12f8_72047833
# - 6938124a12f8: MD5-Hash der ersten 1MB des Videos
# - 72047833: Dateigr√∂√üe in Bytes
```

**Vorteile:**
- ‚úÖ **Gleiche Video-ID** auch bei verschiedenen Dateinamen
- ‚úÖ **Gleiche Video-ID** auch bei verschiedenen Speicherorten
- ‚úÖ **Robust** gegen Dateinamen-√Ñnderungen und -Verschiebungen

### Content-basierte Chunk-Duplikat-Erkennung:
```python
# Beispiel: 5eb63bbbe01eeed093cb22bb8f5acdc3
# - MD5-Hash des normalisierten Chunk-Texts
# - Normalisiert: Gro√ü-/Kleinschreibung, Leerzeichen
```

**Vorteile:**
- ‚úÖ **Erkennt identische Chunks** auch bei verschiedenen Chunking-Strategien
- ‚úÖ **Erkennt identische Chunks** auch bei verschiedenen Chunk-Indizes
- ‚úÖ **Robust** gegen Chunking-Parameter-√Ñnderungen
- ‚úÖ **Verhindert Duplikate** bei mehrfacher Verarbeitung

### Praktische Auswirkungen:

**Szenario 1: Gleiches Video, mehrfache Verarbeitung**
```bash
# Run 1: video_6938124a12f8_72047833 ‚Üí 56 Chunks eingef√ºgt
# Run 2: video_6938124a12f8_72047833 ‚Üí "Video already exists. Skipping processing." ‚úÖ
# Result: Keine Duplikate, keine unn√∂tigen Kosten!
```

**Szenario 2: Gleiches Video, anderer Name**
```bash
# Video: "meeting_2025.mp4" ‚Üí video_6938124a12f8_72047833
# Video: "renamed_meeting.mp4" ‚Üí video_6938124a12f8_72047833 ‚úÖ
# Result: Gleiche Video-ID, Verarbeitung √ºbersprungen!
```

**Szenario 3: Gleiches Video, andere Chunking-Parameter**
```bash
# Chunking mit chunk_size=400 ‚Üí Chunks 0,1,2,3...
# Chunking mit chunk_size=600 ‚Üí Chunks 0,1,2...
# Result: Video-Level Check verhindert Verarbeitung komplett!
```

**Szenario 4: Verschiedene Videos**
```bash
# Video A ‚Üí video_6938124a12f8_72047833
# Video B ‚Üí video_a1b2c3d4e5f6_12345678
# Result: Verschiedene Video-IDs, beide werden verarbeitet!
```

## üöÄ Setup und Installation

### 1. Umgebungsvorbereitung

```bash
# Virtual Environment erstellen
python -m venv venv
source venv/bin/activate  # Linux/Mac
# oder
venv\Scripts\activate     # Windows

# Dependencies installieren
pip install -r requirements.txt
```

### 2. FFmpeg Installation (Windows)

```powershell
# Mit winget installieren
winget install "Gyan.FFmpeg" --accept-package-agreements --accept-source-agreements

# PATH aktualisieren
$env:PATH = [System.Environment]::GetEnvironmentVariable("PATH","Machine") + ";" + [System.Environment]::GetEnvironmentVariable("PATH","User")
```

### 3. Umgebungsvariablen konfigurieren

Kopiere `env_template.txt` zu `.env` und f√ºlle aus:

```bash
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Supabase Configuration
SUPABASE_URL=your_supabase_project_url_here
SUPABASE_PUBLISHABLE_KEY=your_supabase_publishable_key_here
SUPABASE_SECRET_KEY=your_supabase_secret_key_here

# Chunking Configuration
CHUNKING_STRATEGY=semantic
CHUNKING_MAX_CHUNK_SIZE=400
CHUNKING_OVERLAP=50
```

## üöÄ Verwendung

### CLI-Tools

Das System bietet mehrere CLI-Tools f√ºr verschiedene Anwendungsf√§lle:

#### CLI-Tools √úbersicht

| Tool | Zweck | Verwendung |
|------|-------|------------|
| `process_videos.py` | **Empfohlen** - Benutzerfreundliches CLI | `python process_videos.py --directory videos/` |
| `batch_processor.py` | Kern-Engine f√ºr Batch-Verarbeitung | Import in anderen Skripten |
| `tests/test_*.py` | Test-Scripts f√ºr einzelne Komponenten | `python tests/test_mini_agent.py` |

**Warum zwei Batch-Tools?**
- `process_videos.py` = Benutzerfreundliches CLI mit Argument-Parsing
- `batch_processor.py` = Kern-Logik, die von anderen Skripten importiert werden kann

#### 1. Batch-Verarbeitung (Empfohlen)
```bash
# Einzelnes Video verarbeiten
python process_videos.py --directory videos/

# Dry-run (nur anzeigen, nicht verarbeiten)
python process_videos.py --directory videos/ --dry-run

# Mit spezifischer Chunking-Strategie
python process_videos.py --directory videos/ --chunking-strategy semantic
```

#### 2. Robuste Pipeline mit Statistiken
```bash
# Batch-Verarbeitung mit detaillierten Statistiken
python batch_processor.py --directory videos/

# Mit verschiedenen Chunking-Strategien
python batch_processor.py --directory videos/ --chunking-strategy recursive
```

#### 3. Tests
```bash
# Alle Komponenten testen
python tests/test_transcription.py
python tests/test_chunking.py
python tests/test_embedding.py
python tests/test_mini_agent.py
```

### CLI-Optionen (process_videos.py)

| Option | Beschreibung | Beispiel |
|--------|--------------|----------|
| `--directory` | Verzeichnis mit Videos verarbeiten | `--directory videos/` |
| `--files` | Spezifische Dateien verarbeiten | `--files video1.mp4 video2.mp4` |
| `--dry-run` | Nur anzeigen, nicht verarbeiten | `--dry-run` |
| `--max-videos` | Max. Anzahl Videos (f√ºr Tests) | `--max-videos 10` |
| `--chunking-strategy` | Chunking-Strategie w√§hlen | `--chunking-strategy semantic` |
| `--output` | Ausgabe-Verzeichnis f√ºr Transkriptionen | `--output transcriptions/` |

### Verf√ºgbare Chunking-Strategien

| Strategie | Beschreibung | Verwendung |
|-----------|--------------|------------|
| `semantic` | **Empfohlen** - Basierend auf Chroma Research | Beste Balance zwischen Qualit√§t und Performance |
| `recursive` | Hierarchische Text-Aufteilung | Fallback-Option |
| `video_optimized` | Optimiert f√ºr Video-Inhalte | Erweiterte Konfiguration |
| `fixed` | Einfache Zeichen-basierte Aufteilung | Einfache Anwendungsf√§lle |

## üß™ Testing

### 1. Transkription testen

```bash
python tests/test_transcription.py
```

**Erwartetes Ergebnis:**
- Video wird transkribiert
- JSON-Datei in `transcriptions/` gespeichert
- Metadaten extrahiert (Timestamps, Qualit√§t)

### 2. Chunking testen

```bash
python tests/test_chunking.py
```

**Erwartetes Ergebnis:**
- 4 Strategien verglichen
- Semantic Strategy empfohlen
- Timestamps korrekt zugeordnet

### 3. Embeddings testen

```bash
python tests/test_embedding.py
```

**Erwartetes Ergebnis:**
- 1.536-dimensionale Embeddings generiert
- Mock-Daten in `mock_supabase_data.json` gespeichert
- Kosten-Sch√§tzung angezeigt

### 4. Mini Chat Agent testen

```bash
python tests/test_mini_agent.py
```

**Erwartetes Ergebnis:**
- Agent beantwortet Fragen basierend auf Video-Inhalten
- Confidence-Scores und Quellen angezeigt

### 5. Interaktive Chat-Session

```bash
python tests/test_mini_agent.py --interactive
```

**Verf√ºgbare Befehle:**
- `quit` - Session beenden
- `history` - Gespr√§chsverlauf anzeigen  
- `clear` - Verlauf l√∂schen
- Normale Fragen - Antworten basierend auf Video-Inhalten

**Beispiel-Session:**
```
‚ùì Your question: Worum geht es in dem Video?
ü§ñ Answer: Das Video behandelt das Thema Selbstsabotage und Prokrastination...
üìä Confidence: 1.0
üìö Sources used: 3/5

‚ùì Your question: Wer spricht in dem Video?
ü§ñ Answer: Im bereitgestellten Kontext wird nicht explizit erw√§hnt, wer spricht...
üìä Confidence: 1.0
üìö Sources used: 3/5

‚ùì Your question: quit
üëã Goodbye!
```

## üìÅ Projektstruktur

```
ums__chunking/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ transcription/          # Video-Transkription
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ whisper_client.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audio_processor.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata_extractor.py
‚îÇ   ‚îú‚îÄ‚îÄ chunking/              # Semantic Chunking
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ semantic_chunker.py
‚îÇ   ‚îú‚îÄ‚îÄ embedding/             # Embedding-Generierung
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ embedding_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ agent/                # Mini Chat Agent
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mini_chat_agent.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/                # Hilfsfunktionen
‚îÇ       ‚îî‚îÄ‚îÄ transcription_utils.py
‚îú‚îÄ‚îÄ tests/                    # Test-Scripts
‚îú‚îÄ‚îÄ transcriptions/           # Gespeicherte Transkriptionen
‚îú‚îÄ‚îÄ config/                   # Konfiguration
‚îú‚îÄ‚îÄ database/                 # Supabase Schema
‚îî‚îÄ‚îÄ requirements.txt          # Dependencies
```

## üîß Konfiguration

### Chunking-Strategien

| Strategie | Chunk-Gr√∂√üe | Overlap | Verwendung |
|-----------|-------------|---------|------------|
| semantic | 400 | 50 | **Empfohlen** (beste Balance) |
| recursive | 500 | 50 | Fallback-Option |
| video_optimized | 600 | 75 | Erweiterte Konfiguration |
| fixed | 400 | 0 | Einfache Aufteilung |

### Embedding-Konfiguration

- **Model**: text-embedding-3-small
- **Dimensionen**: 1.536
- **Batch-Gr√∂√üe**: 100 (f√ºr Effizienz)
- **Kosten**: $0.00002 pro 1K Tokens

## üóÑÔ∏è Supabase Setup

### ‚ö†Ô∏è **WICHTIG: Neue Supabase API-Keys**

Supabase hat ihre API-Key-Struktur ge√§ndert! Die alten `anon` und `service_role` Keys werden **November 2025** entfernt.

**Neue Keys (empfohlen):**
- **`sb_publishable_...`** - Ersetzt `anon` key (sicher f√ºr Frontend)
- **`sb_secret_...`** - Ersetzt `service_role` key (nur f√ºr Backend)

**Migration:**
1. Gehe zu [Supabase Dashboard](https://supabase.com/dashboard/project/_/settings/api-keys/new)
2. Generiere neue API-Keys
3. Aktualisiere deine `.env` Datei
4. Teste die Verbindung

**Referenz:** [Supabase API Key Changes](https://github.com/orgs/supabase/discussions/29260)

### 1. Tabelle erstellen

```sql
CREATE TABLE video_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    video_id VARCHAR NOT NULL,
    chunk_text TEXT NOT NULL,
    chunk_index INTEGER NOT NULL,
    start_timestamp FLOAT NOT NULL,
    end_timestamp FLOAT NOT NULL,
    embedding VECTOR(1536),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX ON video_chunks USING ivfflat (embedding vector_cosine_ops);
```

### 2. pgvector Extension aktivieren

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

## üöÄ Produktions-Deployment

### 1. Vollst√§ndige Pipeline

```python
from src.embedding.embedding_generator import VideoProcessor
from src.chunking.semantic_chunker import SemanticChunker
from src.transcription.whisper_client import WhisperClient

# Video verarbeiten
processor = VideoProcessor()
chunker = SemanticChunker(strategy="semantic")
whisper = WhisperClient()

# Pipeline ausf√ºhren
transcription = whisper.transcribe_video("video.mp4")
chunks = chunker.chunk_transcription(transcription.segments, "video_id")
success = processor.process_video_chunks(chunks)
```

### 2. Batch-Verarbeitung f√ºr 300 Videos

**Wichtiger Hinweis:** Das System erkennt automatisch bereits verarbeitete Videos und √ºberspringt sie, um Duplikate und unn√∂tige Kosten zu vermeiden.

#### Option A: CLI-Script (empfohlen)

```bash
# Alle Videos in einem Verzeichnis verarbeiten
python process_videos.py --directory videos/

# Spezifische Videos verarbeiten
python process_videos.py --files video1.mp4 video2.mp4

# Mit verschiedenen Chunking-Strategien
python process_videos.py --directory videos/ --chunking-strategy video_optimized

# Nur erste 10 Videos testen
python process_videos.py --directory videos/ --max-videos 10

# Dry-run (zeigen was verarbeitet w√ºrde)
python process_videos.py --directory videos/ --dry-run
```

#### Option B: Python-Script

```python
from batch_processor import BatchVideoProcessor
from pathlib import Path

# Batch-Processor initialisieren
processor = BatchVideoProcessor()

# Alle Videos in einem Verzeichnis verarbeiten
video_directory = Path("videos/")
stats = processor.process_video_directory(video_directory)

# Spezifische Videos verarbeiten
video_files = [Path("video1.mp4"), Path("video2.mp4")]
stats = processor.process_video_list(video_files)

print(f"‚úÖ {stats['processed_videos']} videos processed")
print(f"üí∞ Cost: ${stats['total_cost']:.4f}")
```

## üîç Troubleshooting

### H√§ufige Probleme:

1. **FFmpeg nicht gefunden**
   ```bash
   # Windows: Mit winget installieren
   winget install "Gyan.FFmpeg"
   ```

2. **OpenAI API Key nicht geladen**
   ```bash
   # .env Datei pr√ºfen
   cat .env | grep OPENAI_API_KEY
   ```

3. **Module nicht gefunden**
   ```bash
   # PYTHONPATH setzen
   export PYTHONPATH="."
   ```

4. **Supabase-Verbindung fehlschl√§gt**
   - Credentials in `.env` pr√ºfen
   - Tabelle in Supabase erstellt?
   - pgvector Extension aktiviert?

## üìà Erweiterungsm√∂glichkeiten

### 1. Erweiterte Chunking-Strategien
- Topic-basierte Segmentierung
- Dynamische Chunk-Gr√∂√üen
- Kontext-bewusste Chunking

### 2. Multi-Modal Features
- Video-Thumbnails zu Chunks
- Audio-Features extrahieren
- OCR f√ºr Slides/Text

### 3. Advanced RAG
- Hybride Suche (Vector + Keyword)
- Re-Ranking mit Cross-Encoder
- Context-Compression

### 4. Monitoring & Analytics
- Chunk-Qualit√§ts-Metriken
- User-Interaktion-Tracking
- Performance-Monitoring

## üìö Referenzen

- [Chroma Research: Evaluating Chunking](https://research.trychroma.com/evaluating-chunking)
- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)
- [Supabase pgvector](https://supabase.com/docs/guides/database/extensions/pgvector)
- [LangChain RAG](https://python.langchain.com/docs/use_cases/question_answering/)

## ü§ù Support

Bei Fragen oder Problemen:
1. Checke die Test-Scripts f√ºr Beispiele
2. Pr√ºfe die Logs f√ºr Fehlermeldungen
3. Stelle sicher, dass alle Dependencies installiert sind
4. Verifiziere die API-Keys und Supabase-Credentials

---

**Version**: 1.2.0  
**Letzte Aktualisierung**: September 2025  
**Kompatibilit√§t**: Python 3.8+, Windows/Linux/Mac
