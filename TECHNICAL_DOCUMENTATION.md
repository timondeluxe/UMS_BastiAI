# Umsetzer Video Chunking Pipeline - Technische Dokumentation

## ğŸ¯ Ãœberblick

Die Umsetzer Video Chunking Pipeline ist eine vollstÃ¤ndige LÃ¶sung zur Verarbeitung von Video-Transkripten fÃ¼r intelligente Q&A-Systeme. Sie transkribiert Videos, teilt sie in semantische Chunks, generiert Embeddings und ermÃ¶glicht Retrieval-basierte Antworten.

## ğŸ—ï¸ Architektur

```
Video Input â†’ Transcription â†’ Semantic Chunking â†’ Embedding Generation â†’ Supabase Storage â†’ Mini Chat Agent
```

### Kernkomponenten:

1. **Transcription Pipeline** (`src/transcription/`)
   - OpenAI Whisper API Integration
   - Audio-Extraktion mit FFmpeg
   - Metadaten-Extraktion (Timestamps)
   - **Content-basierte Video-ID-Generierung** (robust gegen Dateinamen-Ã„nderungen)

2. **Semantic Chunking** (`src/chunking/`)
   - Basierend auf Chroma Research (89.7% Recall)
   - Multiple Strategien: semantic, recursive, video_optimized, fixed
   - Optimale Chunk-GrÃ¶ÃŸe: 400 Zeichen mit 50 Zeichen Overlap
   - **Intelligente Timestamp-Zuordnung** (verhindert "0" Timestamps)

3. **Embedding Generation** (`src/embedding/`)
   - OpenAI text-embedding-3-small (1.536 Dimensionen)
   - Batch-Verarbeitung fÃ¼r Effizienz
   - Supabase Integration mit pgvector
   - **Video-Level Duplikat-Erkennung** (verhindert mehrfache Verarbeitung)
   - **Content-basierte Chunk-Duplikat-Erkennung** (robust gegen Chunking-Parameter-Ã„nderungen)

4. **Mini Chat Agent** (`src/agent/`)
   - Retrieval-Augmented Generation (RAG)
   - GPT-4o-mini fÃ¼r Antwort-Generierung
   - Interaktive Chat-Sessions

## ğŸ“Š Performance-Metriken

### Chunking-Ergebnisse (1-Stunden-Video):
- **Input**: 303 Segmente, 3.423 WÃ¶rter
- **Output**: 57 semantic chunks, 365 Zeichen Durchschnitt
- **Strategie**: Semantic (beste Balance)

### Kosten-SchÃ¤tzung:
- **Transkription**: ~$0.006 pro Stunde (Whisper API)
- **Embeddings**: $0.0007 pro Video (text-embedding-3-small)
- **Chat**: $0.0015 pro 1K Tokens (GPT-4o-mini)
- **Total fÃ¼r 300 Videos**: ~$0.21

### Kostenersparnis durch Duplikat-Erkennung:
- **Mehrfache Verarbeitung**: Verhindert unnÃ¶tige Transkriptionen
- **Batch-Runs**: Sicher vor versehentlichen Wiederholungen
- **Entwicklung**: Keine Kosten fÃ¼r Test-Runs
- **Wartung**: Effiziente Updates ohne Duplikate

## ğŸ”§ Aktuelle Verbesserungen

### Intelligente Timestamp-Zuordnung:
- **Problem gelÃ¶st**: Keine "0" Timestamps mehr fÃ¼r Chunks, die nicht am Anfang stehen
- **Realistische Chunk-Dauern**: 10-120 Sekunden statt 20+ Minuten
- **Proportionale Zuordnung**: Basierend auf Chunk-Index und Text-LÃ¤nge
- **Robuste Validierung**: Schutz vor unlogischen Timestamps
- **47x Verbesserung**: Durchschnittsdauer von 22,5 Min auf 0,5 Min reduziert

### Vereinfachte Architektur:
- **Speaker-Detection entfernt**: Whisper unterstÃ¼tzt keine native Speaker-Erkennung
- **Sauberer Code**: Fokus auf die wichtigen Features (Timestamps, Chunking, Embeddings)
- **Bessere Performance**: Weniger Datenverarbeitung ohne Speaker-Logik
- **Wartbarkeit**: Reduzierte KomplexitÃ¤t

## ğŸ”’ Robuste Identifikation

### Video-Level Duplikat-Erkennung:
```python
# 1. Generiere Video-ID (content-basiert)
video_id = self.whisper._generate_video_id(video_file)

# 2. PrÃ¼fe ob Video bereits existiert
existing_check = self.processor.supabase_client.client.table("video_chunks").select("video_id").eq("video_id", video_id).limit(1).execute()

# 3. Ãœberspringe Verarbeitung wenn existiert
if existing_check.data:
    logger.info(f"Video {video_id} already exists in database. Skipping processing.")
    return True
```

**Vorteile:**
- âœ… **Verhindert mehrfache Transkription** (kosteneinsparend)
- âœ… **Verhindert mehrfache Verarbeitung** (zeitsparend)
- âœ… **Robust** gegen Whisper API Nicht-Determinismus
- âœ… **Effizient** durch frÃ¼he Erkennung

### Content-basierte Video-ID-Generierung:
```python
# Beispiel: video_6938124a12f8_72047833
# - 6938124a12f8: MD5-Hash der ersten 1MB des Videos
# - 72047833: DateigrÃ¶ÃŸe in Bytes
```

**Vorteile:**
- âœ… **Gleiche Video-ID** auch bei verschiedenen Dateinamen
- âœ… **Gleiche Video-ID** auch bei verschiedenen Speicherorten
- âœ… **Robust** gegen Dateinamen-Ã„nderungen und -Verschiebungen

### Content-basierte Chunk-Duplikat-Erkennung:
```python
# Beispiel: 5eb63bbbe01eeed093cb22bb8f5acdc3
# - MD5-Hash des normalisierten Chunk-Texts
# - Normalisiert: GroÃŸ-/Kleinschreibung, Leerzeichen
```

**Vorteile:**
- âœ… **Erkennt identische Chunks** auch bei verschiedenen Chunking-Strategien
- âœ… **Erkennt identische Chunks** auch bei verschiedenen Chunk-Indizes
- âœ… **Robust** gegen Chunking-Parameter-Ã„nderungen
- âœ… **Verhindert Duplikate** bei mehrfacher Verarbeitung

### Praktische Auswirkungen:

**Szenario 1: Gleiches Video, mehrfache Verarbeitung**
```bash
# Run 1: video_6938124a12f8_72047833 â†’ 56 Chunks eingefÃ¼gt
# Run 2: video_6938124a12f8_72047833 â†’ "Video already exists. Skipping processing." âœ…
# Result: Keine Duplikate, keine unnÃ¶tigen Kosten!
```

**Szenario 2: Gleiches Video, anderer Name**
```bash
# Video: "meeting_2025.mp4" â†’ video_6938124a12f8_72047833
# Video: "renamed_meeting.mp4" â†’ video_6938124a12f8_72047833 âœ…
# Result: Gleiche Video-ID, Verarbeitung Ã¼bersprungen!
```

**Szenario 3: Gleiches Video, andere Chunking-Parameter**
```bash
# Chunking mit chunk_size=400 â†’ Chunks 0,1,2,3...
# Chunking mit chunk_size=600 â†’ Chunks 0,1,2...
# Result: Video-Level Check verhindert Verarbeitung komplett!
```

**Szenario 4: Verschiedene Videos**
```bash
# Video A â†’ video_6938124a12f8_72047833
# Video B â†’ video_a1b2c3d4e5f6_12345678
# Result: Verschiedene Video-IDs, beide werden verarbeitet!
```

## ğŸš€ Setup und Installation

### 1. Umgebungsvorbereitung

```bash
# Virtual Environment erstellen
python -m venv venv
source venv/bin/activate  # Linux/Mac
# oder
venv\Scripts\activate     # Windows

# Dependencies installieren
pip install -r requirements.txt
```

### 2. FFmpeg Installation (Windows)

```powershell
# Mit winget installieren
winget install "Gyan.FFmpeg" --accept-package-agreements --accept-source-agreements

# PATH aktualisieren
$env:PATH = [System.Environment]::GetEnvironmentVariable("PATH","Machine") + ";" + [System.Environment]::GetEnvironmentVariable("PATH","User")
```

### 3. Umgebungsvariablen konfigurieren

Kopiere `env_template.txt` zu `.env` und fÃ¼lle aus:

```bash
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Supabase Configuration
SUPABASE_URL=your_supabase_project_url_here
SUPABASE_PUBLISHABLE_KEY=your_supabase_publishable_key_here
SUPABASE_SECRET_KEY=your_supabase_secret_key_here

# Chunking Configuration
CHUNKING_STRATEGY=semantic
CHUNKING_MAX_CHUNK_SIZE=400
CHUNKING_OVERLAP=50
```

## ğŸš€ Verwendung

### CLI-Tools

Das System bietet mehrere CLI-Tools fÃ¼r verschiedene AnwendungsfÃ¤lle:

#### CLI-Tools Ãœbersicht

| Tool | Zweck | Verwendung |
|------|-------|------------|
| `process_videos.py` | **Empfohlen** - Benutzerfreundliches CLI | `python process_videos.py --directory videos/` |
| `batch_processor.py` | Kern-Engine fÃ¼r Batch-Verarbeitung | Import in anderen Skripten |
| `tests/test_*.py` | Test-Scripts fÃ¼r einzelne Komponenten | `python tests/test_mini_agent.py` |

**Warum zwei Batch-Tools?**
- `process_videos.py` = Benutzerfreundliches CLI mit Argument-Parsing
- `batch_processor.py` = Kern-Logik, die von anderen Skripten importiert werden kann

#### 1. Batch-Verarbeitung (Empfohlen)
```bash
# Einzelnes Video verarbeiten
python process_videos.py --directory videos/

# Dry-run (nur anzeigen, nicht verarbeiten)
python process_videos.py --directory videos/ --dry-run

# Mit spezifischer Chunking-Strategie
python process_videos.py --directory videos/ --chunking-strategy semantic
```

#### 2. Robuste Pipeline mit Statistiken
```bash
# Batch-Verarbeitung mit detaillierten Statistiken
python batch_processor.py --directory videos/

# Mit verschiedenen Chunking-Strategien
python batch_processor.py --directory videos/ --chunking-strategy recursive
```

#### 3. Tests
```bash
# Alle Komponenten testen
python tests/test_transcription.py
python tests/test_chunking.py
python tests/test_embedding.py
python tests/test_mini_agent.py
```

### CLI-Optionen (process_videos.py)

| Option | Beschreibung | Beispiel |
|--------|--------------|----------|
| `--directory` | Verzeichnis mit Videos verarbeiten | `--directory videos/` |
| `--files` | Spezifische Dateien verarbeiten | `--files video1.mp4 video2.mp4` |
| `--dry-run` | Nur anzeigen, nicht verarbeiten | `--dry-run` |
| `--max-videos` | Max. Anzahl Videos (fÃ¼r Tests) | `--max-videos 10` |
| `--chunking-strategy` | Chunking-Strategie wÃ¤hlen | `--chunking-strategy semantic` |
| `--output` | Ausgabe-Verzeichnis fÃ¼r Transkriptionen | `--output transcriptions/` |

### VerfÃ¼gbare Chunking-Strategien

| Strategie | Beschreibung | Verwendung |
|-----------|--------------|------------|
| `semantic` | **Empfohlen** - Basierend auf Chroma Research | Beste Balance zwischen QualitÃ¤t und Performance |
| `recursive` | Hierarchische Text-Aufteilung | Fallback-Option |
| `video_optimized` | Optimiert fÃ¼r Video-Inhalte | Erweiterte Konfiguration |
| `fixed` | Einfache Zeichen-basierte Aufteilung | Einfache AnwendungsfÃ¤lle |

## ğŸ§ª Testing

### 1. Transkription testen

```bash
python tests/test_transcription.py
```

**Erwartetes Ergebnis:**
- Video wird transkribiert
- JSON-Datei in `transcriptions/` gespeichert
- Metadaten extrahiert (Timestamps, QualitÃ¤t)

### 2. Chunking testen

```bash
python tests/test_chunking.py
```

**Erwartetes Ergebnis:**
- 4 Strategien verglichen
- Semantic Strategy empfohlen
- Timestamps korrekt zugeordnet

### 3. Embeddings testen

```bash
python tests/test_embedding.py
```

**Erwartetes Ergebnis:**
- 1.536-dimensionale Embeddings generiert
- Mock-Daten in `mock_supabase_data.json` gespeichert
- Kosten-SchÃ¤tzung angezeigt

### 4. Mini Chat Agent testen

```bash
python tests/test_mini_agent.py
```

**Erwartetes Ergebnis:**
- Agent beantwortet Fragen basierend auf Video-Inhalten
- Confidence-Scores und Quellen angezeigt

### 5. Interaktive Chat-Session

```bash
python tests/test_mini_agent.py --interactive
```

**VerfÃ¼gbare Befehle:**
- `quit` - Session beenden
- `history` - GesprÃ¤chsverlauf anzeigen  
- `clear` - Verlauf lÃ¶schen
- Normale Fragen - Antworten basierend auf Video-Inhalten

**Beispiel-Session:**
```
â“ Your question: Worum geht es in dem Video?
ğŸ¤– Answer: Das Video behandelt das Thema Selbstsabotage und Prokrastination...
ğŸ“Š Confidence: 1.0
ğŸ“š Sources used: 3/5

â“ Your question: Wer spricht in dem Video?
ğŸ¤– Answer: Im bereitgestellten Kontext wird nicht explizit erwÃ¤hnt, wer spricht...
ğŸ“Š Confidence: 1.0
ğŸ“š Sources used: 3/5

â“ Your question: quit
ğŸ‘‹ Goodbye!
```

## ğŸ“ Projektstruktur

```
ums__chunking/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ transcription/          # Video-Transkription
â”‚   â”‚   â”œâ”€â”€ whisper_client.py
â”‚   â”‚   â”œâ”€â”€ audio_processor.py
â”‚   â”‚   â””â”€â”€ metadata_extractor.py
â”‚   â”œâ”€â”€ chunking/              # Semantic Chunking
â”‚   â”‚   â””â”€â”€ semantic_chunker.py
â”‚   â”œâ”€â”€ embedding/             # Embedding-Generierung
â”‚   â”‚   â””â”€â”€ embedding_generator.py
â”‚   â”œâ”€â”€ agent/                # Mini Chat Agent
â”‚   â”‚   â””â”€â”€ mini_chat_agent.py
â”‚   â””â”€â”€ utils/                # Hilfsfunktionen
â”‚       â””â”€â”€ transcription_utils.py
â”œâ”€â”€ tests/                    # Test-Scripts
â”œâ”€â”€ transcriptions/           # Gespeicherte Transkriptionen
â”œâ”€â”€ config/                   # Konfiguration
â”œâ”€â”€ database/                 # Supabase Schema
â””â”€â”€ requirements.txt          # Dependencies
```

## ğŸ”§ Konfiguration

### Chunking-Strategien

| Strategie | Chunk-GrÃ¶ÃŸe | Overlap | Verwendung |
|-----------|-------------|---------|------------|
| semantic | 400 | 50 | **Empfohlen** (beste Balance) |
| recursive | 500 | 50 | Fallback-Option |
| video_optimized | 600 | 75 | Erweiterte Konfiguration |
| fixed | 400 | 0 | Einfache Aufteilung |

### Embedding-Konfiguration

- **Model**: text-embedding-3-small
- **Dimensionen**: 1.536
- **Batch-GrÃ¶ÃŸe**: 100 (fÃ¼r Effizienz)
- **Kosten**: $0.00002 pro 1K Tokens

## ğŸ—„ï¸ Supabase Setup

### âš ï¸ **WICHTIG: Neue Supabase API-Keys**

Supabase hat ihre API-Key-Struktur geÃ¤ndert! Die alten `anon` und `service_role` Keys werden **November 2025** entfernt.

**Neue Keys (empfohlen):**
- **`sb_publishable_...`** - Ersetzt `anon` key (sicher fÃ¼r Frontend)
- **`sb_secret_...`** - Ersetzt `service_role` key (nur fÃ¼r Backend)

**Migration:**
1. Gehe zu [Supabase Dashboard](https://supabase.com/dashboard/project/_/settings/api-keys/new)
2. Generiere neue API-Keys
3. Aktualisiere deine `.env` Datei
4. Teste die Verbindung

**Referenz:** [Supabase API Key Changes](https://github.com/orgs/supabase/discussions/29260)

### 1. Tabelle erstellen

```sql
CREATE TABLE video_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    video_id VARCHAR NOT NULL,
    chunk_text TEXT NOT NULL,
    chunk_index INTEGER NOT NULL,
    start_timestamp FLOAT NOT NULL,
    end_timestamp FLOAT NOT NULL,
    embedding VECTOR(1536),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX ON video_chunks USING ivfflat (embedding vector_cosine_ops);
```

### 2. pgvector Extension aktivieren

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

## ğŸš€ Produktions-Deployment

### 1. VollstÃ¤ndige Pipeline

```python
from src.embedding.embedding_generator import VideoProcessor
from src.chunking.semantic_chunker import SemanticChunker
from src.transcription.whisper_client import WhisperClient

# Video verarbeiten
processor = VideoProcessor()
chunker = SemanticChunker(strategy="semantic")
whisper = WhisperClient()

# Pipeline ausfÃ¼hren
transcription = whisper.transcribe_video("video.mp4")
chunks = chunker.chunk_transcription(transcription.segments, "video_id")
success = processor.process_video_chunks(chunks)
```

### 2. Batch-Verarbeitung fÃ¼r 300 Videos

**Wichtiger Hinweis:** Das System erkennt automatisch bereits verarbeitete Videos und Ã¼berspringt sie, um Duplikate und unnÃ¶tige Kosten zu vermeiden.

#### Option A: CLI-Script (empfohlen)

```bash
# Alle Videos in einem Verzeichnis verarbeiten
python process_videos.py --directory videos/

# Spezifische Videos verarbeiten
python process_videos.py --files video1.mp4 video2.mp4

# Mit verschiedenen Chunking-Strategien
python process_videos.py --directory videos/ --chunking-strategy video_optimized

# Nur erste 10 Videos testen
python process_videos.py --directory videos/ --max-videos 10

# Dry-run (zeigen was verarbeitet wÃ¼rde)
python process_videos.py --directory videos/ --dry-run
```

#### Option B: Python-Script

```python
from batch_processor import BatchVideoProcessor
from pathlib import Path

# Batch-Processor initialisieren
processor = BatchVideoProcessor()

# Alle Videos in einem Verzeichnis verarbeiten
video_directory = Path("videos/")
stats = processor.process_video_directory(video_directory)

# Spezifische Videos verarbeiten
video_files = [Path("video1.mp4"), Path("video2.mp4")]
stats = processor.process_video_list(video_files)

print(f"âœ… {stats['processed_videos']} videos processed")
print(f"ğŸ’° Cost: ${stats['total_cost']:.4f}")
```

## ğŸ” Troubleshooting

### HÃ¤ufige Probleme:

1. **FFmpeg nicht gefunden**
   ```bash
   # Windows: Mit winget installieren
   winget install "Gyan.FFmpeg"
   ```

2. **OpenAI API Key nicht geladen**
   ```bash
   # .env Datei prÃ¼fen
   cat .env | grep OPENAI_API_KEY
   ```

3. **Module nicht gefunden**
   ```bash
   # PYTHONPATH setzen
   export PYTHONPATH="."
   ```

4. **Supabase-Verbindung fehlschlÃ¤gt**
   - Credentials in `.env` prÃ¼fen
   - Tabelle in Supabase erstellt?
   - pgvector Extension aktiviert?

## ğŸ“ˆ ErweiterungsmÃ¶glichkeiten

### 1. Erweiterte Chunking-Strategien
- Topic-basierte Segmentierung
- Dynamische Chunk-GrÃ¶ÃŸen
- Kontext-bewusste Chunking

### 2. Multi-Modal Features
- Video-Thumbnails zu Chunks
- Audio-Features extrahieren
- OCR fÃ¼r Slides/Text

### 3. Advanced RAG
- Hybride Suche (Vector + Keyword)
- Re-Ranking mit Cross-Encoder
- Context-Compression

### 4. Monitoring & Analytics
- Chunk-QualitÃ¤ts-Metriken
- User-Interaktion-Tracking
- Performance-Monitoring

## ğŸ“š Referenzen

- [Chroma Research: Evaluating Chunking](https://research.trychroma.com/evaluating-chunking)
- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)
- [Supabase pgvector](https://supabase.com/docs/guides/database/extensions/pgvector)
- [LangChain RAG](https://python.langchain.com/docs/use_cases/question_answering/)

## ğŸ¤ Support

Bei Fragen oder Problemen:
1. Checke die Test-Scripts fÃ¼r Beispiele
2. PrÃ¼fe die Logs fÃ¼r Fehlermeldungen
3. Stelle sicher, dass alle Dependencies installiert sind
4. Verifiziere die API-Keys und Supabase-Credentials

---

**Version**: 1.2.0  
**Letzte Aktualisierung**: September 2025  
**KompatibilitÃ¤t**: Python 3.8+, Windows/Linux/Mac
